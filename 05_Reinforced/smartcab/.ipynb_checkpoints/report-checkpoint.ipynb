{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report - Reinforced Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Implement a Basic Driving Agent\n",
    "\n",
    "**Task:**\n",
    "To begin, your only task is to get the smartcab to move around in the environment. At this point, you will not be concerned with any sort of optimal driving policy. Note that the driving agent is given the following information at each intersection:\n",
    "•\tThe next waypoint location relative to its current location and heading.\n",
    "•\tThe state of the traffic light at the intersection and the presence of oncoming vehicles from other directions.\n",
    "•\tThe current time left from the allotted deadline.\n",
    "To complete this task, simply have your driving agent choose a random action from the set of possible actions (None, 'forward', 'left', 'right') at each intersection, disregarding the input information above. Set the simulation deadline enforcement, enforce_deadline to False and observe how it performs.\n",
    "\n",
    "**QUESTION:** Observe what you see with the agent's behavior as it takes random actions. Does thesmartcab eventually make it to the destination? Are there any other interesting observations to note?\n",
    "\n",
    "**Anwser:** I implemented a random action generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Select action according to your policy\n",
    "possible_directions = (None, 'forward', 'left', 'right')\n",
    "action = random.choice(possible_directions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The red car stops at every red light correctly and chooses a random action at a green light (None, 'forward', 'left', 'right'). Eventually, it reaches the destination by luck after a long time. All the other cars seem to move randomly too. \n",
    "\n",
    "<img src=\"1.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inform the Driving Agent\n",
    "Now that your driving agent is capable of moving around in the environment, your next task is to identify a set of states that are appropriate for modeling the smartcab and environment. The main source of state variables are the current inputs at the intersection, but not all may require representation. You may choose to explicitly define states, or use some combination of inputs as an implicit state. At each time step, process the inputs and update the agent's current state using the self.state variable. Continue with the simulation deadline enforcementenforce_deadline being set to False, and observe how your driving agent now reports the change in state as the simulation progresses.\n",
    "\n",
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Update state\n",
    "state = {}\n",
    "state['light'] = inputs['light']\n",
    "state['oncoming'] = inputs['oncoming']\n",
    "state['left'] = inputs['left']\n",
    "state['next_waypoint'] = self.get_next_waypoint()\n",
    "self.state = state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION:** What states have you identified that are appropriate for modeling the smartcab and environment? Why do you believe each of these states to be appropriate for this problem?\n",
    "\n",
    "**Answer:** I chose 4 states in total:\n",
    "    - light\n",
    "    - oncoming\n",
    "    - left\n",
    "    - next_waypoint\n",
    "    \n",
    "I did not include \"right\", because it does not affect our agent:\n",
    "    - if our light is \"green\", the right car's light is \"red\" (or if it wants to turn right on a red light, it has to give us the right of way)\n",
    "    - if our light is \"red\" and we want to turn right, the right car can not affect us (I was not sure about the US-traffic rules. It seems that there would be a exception, if the right car wants to make a u-turn. http://arstechnica.com/civis/viewtopic.php?t=67324 . But this is not included in our simulation, so it does not matter)\n",
    "    \n",
    "**OPTIONAL:** How many states in total exist for the smartcab in this environment? Does this number seem reasonable given that the goal of Q-Learning is to learn and make informed decisions about each state? Why or why not?\n",
    "\n",
    "**Anwer:**\n",
    "    - light {red, green} -> 2\n",
    "    - oncoming {None, 'forward', 'left', 'right'} -> 4\n",
    "    - left {None, 'forward', 'left', 'right'} -> 4\n",
    "    - next_waypoint {'forward', 'left', 'right'} -> 3\n",
    "    \n",
    "2x4x4x3 = **96**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3. Implement a Q-Learning Driving Agent\n",
    "\n",
    "With your driving agent being capable of interpreting the input information and having a mapping of environmental states, your next task is to implement the Q-Learning algorithm for your driving agent to choose the best action at each time step, based on the Q-values for the current state and action. Each action taken by the smartcab will produce a reward which depends on the state of the environment. The Q-Learning driving agent will need to consider these rewards when updating the Q-values. Once implemented, set the simulation deadline enforcement enforce_deadline to True. Run the simulation and observe how the smartcab moves about the environment in each trial.\n",
    "\n",
    "The formulas for updating Q-values can be found in this video.\n",
    "\n",
    "**QUESTION:** What changes do you notice in the agent's behavior when compared to the basic driving agent when random actions were always taken? Why is this behavior occurring?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
